{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uva_seal.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Kafka Introduction\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "### SOURCES\n",
    "\n",
    "https://kafka.apache.org/intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVES\n",
    "- Understand the benefits of storing data in logs instead of databases\n",
    "- Understand the use cases for Kafka\n",
    "- Differentiate between Producers and Consumers\n",
    "- Understand the benefits of decoupling Producers from Consumers, and the Pub/Sub model\n",
    "- Understand the benefits of Topic Partitioning\n",
    "- Identify how Kafka provides Scalability and Durability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCEPTS\n",
    "\n",
    "- Events\n",
    "- Logs\n",
    "- Event Streaming\n",
    "- Topics\n",
    "- Durability\n",
    "- Producers\n",
    "- Consumers\n",
    "- Topic Partitioning\n",
    "- Offsets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Apache Kafka?\n",
    "\n",
    "Open-source, distributed event streaming platform for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.\n",
    "\n",
    "As of July 2021, used by more than 80% of Fortune 100 companies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Objects: Things and Events\n",
    "\n",
    "Databases store **things** that have a **state**...cars, customers, ...\n",
    "\n",
    "Many dynamic things can be more naturally thought of as **events** ... hospital admission, patient treatment, website session, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to store events in databases...does each dose of a medication get a record? Maybe other pieces of information need to be added later? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs\n",
    "\n",
    "Instead, can store events in a `log`  \n",
    "A log is ordered sequence of events, with some state info  \n",
    "Logs are easy to think about, and build at scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logfile_example.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Streaming  \n",
    "\n",
    "The practice of capturing data in real-time from event sources like `databases`, `sensors`, `mobile devices`, `cloud services`, and `software applications` in the form of streams of events \n",
    "\n",
    "- durably stored for later retrieval  \n",
    "\n",
    "- manipulate, process, and react to the event streams in real-time as well as retrospectively  \n",
    "\n",
    "- route the event streams to different destination technologies as needed (e.g., **Spark**, Tableau) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Kafka Does\n",
    "\n",
    "`Kafka` is a system for managing logs \n",
    "\n",
    "Logs are organized into `topics`  \n",
    "\n",
    "A topic is an ordered collection of events stored in **durable** way (written to disk and replicated)\n",
    "\n",
    "Topics can be small or enormous\n",
    "\n",
    "Example: **Slack**. Topics are slotted into *channels*, and users can join a channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Topics are Used\n",
    "\n",
    "Write lots of small programs instead of large monolith  \n",
    "\n",
    "Each service can talk to (consume) Kafka topics\n",
    "\n",
    "Then produce the message to another Kafka topic\n",
    "\n",
    "Now there's persistent data in streams\n",
    "\n",
    "It is possible to build new services that use these streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Old Publishing Model\n",
    "\n",
    "The producers of content needed to track their consumers (who is signed up to receive Time magazine?)\n",
    "\n",
    "Needs to be maintained over time, and scalability is a challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pub/Sub Model uses Producers and Consumers\n",
    "\n",
    "**Producers** are client applications that publish (write) events to various Kafka topics\n",
    "\n",
    "**Consumers** are client applications that subscribe to (read and process) the events from topics of interest \n",
    "\n",
    "Producers and Consumers are fully decoupled and agnostic of each other...this allows the service to scale.  \n",
    "\n",
    "Producers never need to wait for consumers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pub/Sub Messaging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pubsub.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics are Partitioned\n",
    "\n",
    "*How do things scale?*\n",
    "\n",
    "A topic is spread over a number of \"buckets\" located on different Kafka brokers (aka nodes or servers). \n",
    "\n",
    "This distributed placement of data is important for scalability.  \n",
    "Allows client applications to both read and write the data from/to many brokers at the same time. \n",
    "\n",
    "When new event is published to a topic, it is appended to one of the topic's partitions.  \n",
    "Events with the same event key (e.g., a patient ID) are written to same partition, \n",
    "\n",
    "Kafka guarantees any consumer of a topic-partition will always read that partition's events in exactly the same order as they were written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"partitioned_topics.png\" alt=\"drawing\" width=\"800\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions are Replicated\n",
    "\n",
    "For **fault-tolerance** and **high availability**, each topic is replicated.\n",
    "\n",
    "The **leader** is the first broker that receives the data partition. The leader sends data to other available brokers, called **followers**.\n",
    "\n",
    "The follower is also known as an **in-sync replica**. \n",
    "\n",
    "Replication can be across geographies, datacenters.  \n",
    "In this way, multiple brokers keep copies of the data.\n",
    "\n",
    "It is common to use replication factor = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Consumer maintains its offset per topic partition.  \n",
    "Consumers remember offset where they left off reading.  \n",
    "They can request logs from that offset later, or a different offset. \n",
    "\n",
    "Note: The Producer is NOT responsible for maintaining Consumer offsets.\n",
    "\n",
    "Example: returning to Slack, the app will show the last message read in a channel. Your machine tracks this position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kafka_offsets.png\" alt=\"drawing\" width=\"400\">  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS5110 Spark 3.3",
   "language": "python",
   "name": "ds5110_spark3.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
