{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Stores\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: September 21, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SOURCES: \n",
    "\n",
    "- [Vector Stores](https://js.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "\n",
    "- [What is a Vector Database?](https://www.pinecone.io/learn/vector-database/)\n",
    "\n",
    "- [What are vector embeddings](https://www.pinecone.io/learn/vector-embeddings-for-developers/)\n",
    "\n",
    "- [Word2Vec](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "- [RAG pattern](https://vitalflux.com/retrieval-augmented-generation-rag-llm-examples/)\n",
    "\n",
    "### OBJECTIVES\n",
    "\n",
    "- \n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Vector embedding\n",
    "- Similarity of embeddings\n",
    "- Vector store\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background on Vector Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Natural Language Processing (NLP) classifiers used presence or count of words in documents.\n",
    "\n",
    "A large leap forward used vector representations (**embeddings**) of documents\n",
    "\n",
    "The embeddings are vectors of fixed size like 64 or 128; values are floats.\n",
    "\n",
    "All kinds of media are now embedded: documents, videos, images, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./embed_examples.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the elements are interpretable. \n",
    "\n",
    "In this example, (dog/puppy/cat) elements have similar sign & direction for some columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects as Vectors\n",
    "\n",
    "In the figure below, each object is projected into 2D space as a vector.  \n",
    "There is a notion of object similarity which can be measured by distance between points.  \n",
    "The light blue objects (represented as points) are more similar than the other objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./vector_space.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "Different embeddings can be compared using a similarity score like *cosine similarity*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./cosine_sim.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training and Use\n",
    "\n",
    "Embeddings are formed by training a neural network on the data and taking the last hidden layer.\n",
    "\n",
    "One of the earliest models was [Word2Vec](https://en.wikipedia.org/wiki/Word2vec)\n",
    "\n",
    "After objects are represented as vectors, they can be stored and reused later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flow looks like this:\n",
    "\n",
    "```\n",
    "raw data -> embedding model -> vector embedding\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage\n",
    "\n",
    "The vectors can be stored in a traditional database (relational or NoSQL)...  \n",
    "...but specialized databases have emerged to efficiently store, compare, and search on embeddings.\n",
    "\n",
    "These are called **vector stores**  \n",
    "\n",
    "Examples:\n",
    "\n",
    "- Pinecone\n",
    "- OpenSearch\n",
    "\n",
    "We will look at a Pinecone demo in this module\n",
    "\n",
    "[fill in how they work]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embedding Use Cases\n",
    "\n",
    "Some important use cases are:\n",
    "\n",
    "- **Search** - Embeddings can represent deeper attributes of an object than keywords. \n",
    "  They can be much more effective in getting good search results like this:  \n",
    "  - User query can be embedded (using a specific embedding model)\n",
    "  - Each piece of content was embedded earlier (using that same embedding model)\n",
    "  - Similarity between query embedding and each content embedding is calculated\n",
    "  - Highest-scoring matches are selected\n",
    "  - Apply any relevant filters\n",
    "  - Return top results\n",
    "  \n",
    "- **Question answering** - better search allows for better ability to answer questions  \n",
    "  \n",
    "  \n",
    "- **Recommendation** - better search allows for more relevant recommendations  \n",
    "   Example: Given attribute information for users and items, recommend items with similar vectors\n",
    "  \n",
    "- **Generative AI** - GenAI models can produce new content and they can power chatbots  \n",
    "  One major risk is *hallucination*. If there is a request where the model wasn't sufficiently trained, it may return nonsense.  \n",
    "  Popular approach now is *RAG* - retrieval augmented generation   \n",
    "  \n",
    "  \n",
    "RAG does this:\n",
    "  - Embed the query\n",
    "  - Search for most similar content embedding\n",
    "  - Include matching content in user prompt: \"Based on the content below, tell me about neural networks.\"  \n",
    "  - Large language model (LLM) constructs and returns result based on prompt + context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./rag.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "[fill this in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
