## INTRODUCTION

In this module, you will learn about one of the fundamental data types in Spark: the resilient distributed dataset (RDD).  
Next, you will learn about how to run a Spark application on a cluster.

Note: The programming assignment this week is one of the more challenging ones. Be sure to leave adequate time.
 
## LEARNING OUTCOMES

At the conclusion of this module, you should be able to:

- Demonstrate how to use RDDs and Pair RDDs in data analysis tasks
- Identify the conceptual framework of running Spark on a cluster
- Define data system reliability, scalability, and maintainabilityÂ 
- Progress toward executing an end-to-end predictive modeling project using a large dataset
