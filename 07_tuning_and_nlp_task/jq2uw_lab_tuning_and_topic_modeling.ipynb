{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab: Tuning and Topic Modeling\n",
    "\n",
    "### University of Virginia\n",
    "### DS 7200: Distributed Computing\n",
    "### Last Updated: August 20, 2023\n",
    "\n",
    "\n",
    "#### Jiaxing Qiu\n",
    "#### JQ2UW\n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**  \n",
    "In this assignment, you will do three things:\n",
    "1) Tune a logistic regression model  \n",
    "2) Label-balance a dataset  \n",
    "3) Run the Topic Modeling notebook, making small tweaks and capturing results  \n",
    "\n",
    "**TOTAL POINTS: 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"data preprocessing\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update to match your path\n",
    "directory_path = './'\n",
    "full_path_to_file = os.path.join(directory_path, 'breast_cancer_wisconsin.csv')\n",
    "path_to_data = os.path.join(full_path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class = 2 for benign (negative class, 4 for malignant (positive class)\n",
    "target = 'class'\n",
    "positive_label = 4\n",
    "negative_label = 2\n",
    "\n",
    "SEED = 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca = spark.read.csv(path_to_data, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- clump_thickness: integer (nullable = true)\n",
      " |-- uniformity_cell_size: integer (nullable = true)\n",
      " |-- uniformity_cell_shape: integer (nullable = true)\n",
      " |-- marginal_adhesion: integer (nullable = true)\n",
      " |-- single_epithelial_cell_size: integer (nullable = true)\n",
      " |-- bare_nuclei: string (nullable = true)\n",
      " |-- bland_chromatin: integer (nullable = true)\n",
      " |-- normal_nucleoli: integer (nullable = true)\n",
      " |-- mitoses: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brca.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    4|  241|\n",
      "|    2|  458|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute distribution of target variable\n",
    "brca.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:  Cross Validate a Logistic Regression Model\n",
    "i) (**4 PTS**) This task has the following requirements:\n",
    "- import necessary modules\n",
    "- use these features as predictors: `clump_thickness`,`uniformity_cell_size`,`uniformity_cell_shape`,`marginal_adhesion`  \n",
    "- `class` is response variable. apply recoding as needed. hint: save as new variable.\n",
    "- use 3 folds in the cross validator object\n",
    "- use BinaryClassificationEvaluator\n",
    "- logistic regression model with `maxIter`=10  \n",
    "- tuning grid with `regParam` values of 0.1 and 0.01\n",
    "- finally, print the average metrics based on each `regParam` value. the attribute `avgMetrics` in the cv model will hold these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regParam = 0.1, AUC-ROC = 0.9911\n",
      "For regParam = 0.01, AUC-ROC = 0.9905\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Read in data again \n",
    "brca = spark.read.csv(path_to_data, header=True, inferSchema=True)\n",
    "\n",
    "# Define the features and response variable\n",
    "selected_features = ['clump_thickness', 'uniformity_cell_size', 'uniformity_cell_shape', 'marginal_adhesion']\n",
    "\n",
    "# Recode the target variable into binary labels\n",
    "target = 'class'\n",
    "positive_label = 4\n",
    "negative_label = 2\n",
    "brca = brca.withColumn('label', when(brca[target] == positive_label, 1).otherwise(0))\n",
    "\n",
    "# Create a feature vector using the selected features\n",
    "feature_assembler = VectorAssembler(inputCols=selected_features, outputCol='features')\n",
    "brca = feature_assembler.transform(brca)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "# Create a parameter grid for hyperparameter tuning\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(lr.regParam, [0.1, 0.01])\n",
    "              .build())\n",
    "\n",
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
    "\n",
    "# Create a CrossValidator object with 3 folds\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Fit the model and perform cross-validation\n",
    "cv_model = crossval.fit(brca)\n",
    "\n",
    "# Print the average metrics based on each regParam value\n",
    "for idx, metric in enumerate(cv_model.avgMetrics):\n",
    "    print(f'For regParam = {param_grid[idx][lr.regParam]}, AUC-ROC = {metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:  Balancing a DataFrame with Downsampling  \n",
    "i) (**2 PTS**) Write a function to implement downsampling.  Enter code into the cell containing the `downsample` function.  \n",
    "\n",
    "INPUTS  \n",
    "* df               - Spark dataframe  \n",
    "* target           - string, target variable  \n",
    "* positive_label   - integer, value of positive label  \n",
    "* negative_label   - integer, value of negative label  \n",
    "\n",
    "OUTPUT  \n",
    "balanced spark dataframe  \n",
    "\n",
    "Downsampling = sample from larger class to match smaller class  \n",
    "\n",
    "**Example:**  \n",
    "\n",
    "INITIAL STATE  \n",
    "Smaller class has 100 records  \n",
    "Larger class size has 400 records\n",
    "\n",
    "ACTION  \n",
    "Sample 100 records from larger class, without replacement  \n",
    "Retain all records from smaller class\n",
    "\n",
    "END STATE    \n",
    "This produces a balanced dataset containing 100 records from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def downsample(df, target, positive_label, negative_label):\n",
    "    # Calculate the number of records in each class\n",
    "    num_positive = df.filter(df[target] == positive_label).count()\n",
    "    num_negative = df.filter(df[target] == negative_label).count()\n",
    "\n",
    "    # Determine the smaller and larger classes\n",
    "    if num_positive < num_negative:\n",
    "        smaller_class_label = positive_label\n",
    "        larger_class_label = negative_label\n",
    "        smaller_class_count = num_positive\n",
    "    else:\n",
    "        smaller_class_label = negative_label\n",
    "        larger_class_label = positive_label\n",
    "        smaller_class_count = num_negative\n",
    "\n",
    "    # Calculate the fraction for downsampling the larger class\n",
    "    fraction = min(num_positive, num_negative) / max(num_positive, num_negative)\n",
    "\n",
    "    # Sample records from the larger class without replacement\n",
    "    downsampled_df = df.filter(df[target] == smaller_class_label).union(\n",
    "        df.filter(df[target] == larger_class_label).sample(False, fraction)\n",
    "    )\n",
    "\n",
    "    return downsampled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) **(1 PT)** Print the target distribution from this balanced dataset, to show the label counts nearly match.\n",
    "\n",
    "#### IMPORTANT NOTE:\n",
    "Sampling won't produce the exact fraction you request. In order to sample efficiently, Spark uses Bernouilli Sampling. \n",
    "Each row is assigned a probability of being included. If you request a 10% sample, each row individually has a 10% chance of being included but this does not guarantee an exact 10% sample   \n",
    "(it should be close, however)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    4|  241|\n",
      "|    2|  264|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data again \n",
    "brca = spark.read.csv(path_to_data, header=True, inferSchema=True)\n",
    "\n",
    "balanced_brca = downsample(brca, 'class', 4, 2)\n",
    "\n",
    "# compute distribution of target variable\n",
    "target = 'class'\n",
    "balanced_brca.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Topic Modeling\n",
    "\n",
    "In this exercise, you will run the `topic_modeling.ipynb` notebook and answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) **(1 PT)** For the first headline in the dataset, the code processes it and extracts tokens. Provide a list of the tokens.\n",
    "\n",
    "+-------------+--------------------------------------------------+  \n",
    "|publish_date | headline_text                                     |  \n",
    "+-------------+--------------------------------------------------+  \n",
    "|20030219     | aba decides against community broadcasting licence|  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[aba, decid, commun, broadcast, licenc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) **(1 PT)** The code created a count vectorizer and extracted features. \n",
    "\n",
    "`cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=500, minDF=3.0)`\n",
    "\n",
    "The first document had six tokens and the feature vector looked like this:\n",
    "\n",
    "(500, [118, 498], [1.0, 1.0])   \n",
    "\n",
    "Explain why there are only two non-zero elements in this feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anwser is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index 118 corresponds to one feature, and it has a count of 1.0.\n",
    "- Index 498 corresponds to another feature, and it also has a count of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) **(1 PT)** Change the number of topics to 2, rerun LDA, and visualize the topics by showing the topic words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic: 0\n",
    "*************************\n",
    "u\n",
    "iraq\n",
    "polic\n",
    "council\n",
    "sai\n",
    "claim\n",
    "warn\n",
    "water\n",
    "plan\n",
    "world\n",
    "*************************\n",
    "topic: 1\n",
    "*************************\n",
    "war\n",
    "man\n",
    "u\n",
    "new\n",
    "win\n",
    "iraqi\n",
    "anti\n",
    "call\n",
    "govt\n",
    "iraq\n",
    "*************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
