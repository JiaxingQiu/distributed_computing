
## INTRODUCTION TO THE MODULE

In this first module, you will log in to Rivanna and start working with Jupyter Notebooks.  
You will learn about MapReduce, which is a framework for working with massive data sets in a distributed architecture.  
Next, you'll learn the basics of Apache Spark, such as the use cases it solves and how it works.  
Finally, you will see some PySpark code in action, including a short application that does a word count on text.


## LEARNING OUTCOMES

At the conclusion of this module, you should be able to:

- Describe the high-level steps in big data processing
- Demonstrate how to work with Jupyter Notebooks
- Describe the MapReduce framework for big data analytics
- Delineate Spark basic architecture and functionality
- Progress toward executing an end-to-end predictive modeling project using a large dataset
